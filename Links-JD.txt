1.

Link: https://www.sciencedirect.com/science/article/pii/S1877050917309626?via%3Dihub

Mohammed A. Al-Maqri, Mohamed Othman, Borhanuddin Mohd Ali, Zurina Mohd Hanapi, An efficient HCCA scheduler for video streaming with QoS support,
Procedia Computer Science, Volume 109, 2017, Pages 116-123, ISSN 1877-0509, https://doi.org/10.1016/j.procs.2017.05.302.

“Recent years have witnessed a rapid growth of ubiquitous applications in the Internet with a vast spread of multi-media streams. This makes providing differentiated Quality of Service (QoS) for such applications in Wireless Local Area Networks (WLANs) very challenging task.”

“Two-third of all traffics in the networks will be video by 2017 according to Cisco Visual Networking Index [7].This motivates many researches to be carried out to improve the QoS provisioning in WLANs in terms of supporting QoS for such streams. Recently, Motion Picture Experts Group type 4 (MPEG–4/H.264) has become a prominent video the internet due to its scalability, error robustness and network-friendly features [8]. In HCCA, scheduling VBR streams with fixed TXOP throughout their lifetime can provide sufficient yet not favorable service quality as the data rate of such streams are likely varied from its mean characteristics during the time. This can lead to a noticeable increase in the packet delay and deterioration in channel utilization.”

“The limited transmission rate, to a few kilobits per second, in wireless environment has led to evolve of low-bit-rate video coding such as H.263. Consequently, many efforts have been made so as to improve the multimedia compression algorithms providing a higher throughput at a lower error rate, which allow the transmission of low bit-rate up to tens of kbitis or less video streams over wireless networks. The variable bit rate nature of compressed video inspires a major challenge to the transmission of video streams over WLANs.”

2.

Link: https://link-springer-com.libproxy.mst.edu/article/10.1007%2Fs11277-019-06606-5

Pedroso, C.M., da Silva, C.A.G., Barbosa Junior, J.A. et al. A Low-Complexity Scheduler to Improve the Number of Satisfied Video Streaming Users in LTE. Wireless Pers Commun 109, 1121–1132 (2019). https://doi-org.libproxy.mst.edu/10.1007/s11277-019-06606-5

“The ongoing development of mobile communication networks has led to an expressive growth in capacity demand, mainly due to video streaming services, which together with the Internet of Things sector represent a challenge for the mobile network operators.”

“The use of strict quality of service parameters can lead to global resource starvation, where no user can be served with the resources available.”

“The performance evaluation was done through computer simulations, using peak signal-to-noise ratio (PSNR) to compare the quality delivered by competing algorithms, and the number of users who are given enough resources to play video with quality.”

“According to a study conducted by Cisco [1], the traffic generated by video streaming applications on mobile networks is expanding. The forecast indicates that in 2019, close to 79% of the total mobile network traffic will be generated by video streaming. In 2018, the equivalent of one million minutes of videos will be transmitted each second. It is also expected to see an increase of video resolution, which in 2018 should have 11% of videos with Ultra HD standard (4 K).”

“Channel-aware/QoS-unaware scheduling strategies use CQI reporting to improve performance metrics such as fairness in resource sharing, throughput, delay, or jitter. Examples of such strategies are Proportional Fair (PF) and Maximum Throughput (MT), but there are many others available [5–8].”

3.

Link: https://dl-acm-org.libproxy.mst.edu/doi/abs/10.1145/2638404.2638489

Doowon Kim, Jinsuk Baek, and Paul S. Fisher. 2014. Adaptive video streaming over HTTP. In Proceedings of the 2014 ACM Southeast Regional Conference (ACM SE ’14). Association for Computing Machinery, New York, NY, USA, Article 26, 1–3. DOI:https://doi-org.libproxy.mst.edu/10.1145/2638404.2638489

“Traditionally, RTSP (Real-Time Streaming Protocol)/RTP (Real-time Transport Protocol) [2] or RTMP (Real-Time Message Protocol) [3] is used for video stream delivery. The RTSP uses port 554 by default, which is usually blocked by firewalls. Thus, a user using NAT or a firewall cannot use this protocol unless the port is opened. The RTMP is a proprietary protocol so that its usage can be restricted because it requires more cost to deploy and maintain a streaming server for these protocols comparing to a HTTP web server using Apache.”

“All mentioned schemes have two things in common; (1) they use the MPEG-4 H.264 codec, and (2) they switch the quality of streams based CPU usages and the bandwidth of the client. In order to provide better video quality over the existing schemes, the proposed scheme requires the client to send feedback of its current information to the streaming server because the streaming
server is not able to know the information, but only the
downloading speeds of video files.”

4.

Link: https://dl-acm-org.libproxy.mst.edu/doi/abs/10.1145/2387191.2387194

Pablo Piñol, Otoniel López, Miguel Martínez, José Oliver, and Manuel P. Malumbres. 2012. Modeling video streaming over VANETs. Proceedings of the 7th ACM workshop on Performance monitoring and measurement of heterogeneous wireless and wired networks. Association for Computing Machinery, New York, NY, USA, 7–14. DOI:https://doi-org.libproxy.mst.edu/10.1145/2387191.2387194

5.

Link: https://ieeexplore-ieee-org.libproxy.mst.edu/document/6855024

Y. Li, H. Jia, C. Zhu, M. Li, X. Xie and W. Gao, "Low-delay window-based rate control scheme for video quality optimization in video encoder," 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), Florence, 2014, pp. 7333-7337.

“Modern video coding standards such as MPEG-2 [1], H.264/AVC [2] and AVS [3] are widely used for their excellent performance in video compression. However, in certain real-time encoding applications, such as video stream transmission and video communication etc., there exits strict constraints of bit rate and system latency. Meanwhile, the consistency of video quality is also required to be considered. Under these situations, rate control aims at achieving both shortened system latency and consistent video quality for the required bit rate budget.

Typical rate control can be classified as two categories: constant bit rate (CBR) and variable bit rate (VBR). In CBR applications, a short-term average bit rate must be reached regardless of the frame's characteristic. Since the video contents vary from frame to frame, CBR will cause the unavoidable fluctuation of video quality. On the other hand, VBR usually uses the global information of video content to allocate bits among different frames, which can guarantee the uniform video quality. However, this mechanism needs a two-pass or multi-pass encoding process, which is not suitable for real-time encoding application.”

“In summary, the balancing of encoder buffer latency and consistent video quality is not discussed sufficiently in these above-mentioned methods. In this paper, we firstly analyze the constraint of buffer latency and the definition of consistent video quality. Then a window-based rate control scheme is proposed with one window for controlling the rate and latency, while the other window for optimizing video quality.”

“For a given bit budget, not only the high encoding quality of each frame needs to be achieved, but also the fluctuation of the video quality should be minimized for entire sequence in order to maintain a good viewing experience. Since the global video characteristic is not available in one-pass realtime encoding process, the consistent video quality should concern the variance of distortion for all previously encoded frames in respect of the current frame [...]”

“In this paper, we first analyze the constraints of buffer latency and consistent video quality. Then a window-based rate control scheme is proposed with one window for controlling the rate and latency, while the other window for consistent video quality. By applying low complexity frame level rate-distortion model, our proposed method shows an excellent performance in balancing the encoder buffer latency and consistent video quality.”

6.

Link: https://dl-acm-org.libproxy.mst.edu/doi/10.1145/509907.509937

Wun-Tat Chan, Tak-Wah Lam, Hing-Fung Ting, and Wai-Ha Wong. 2002. A unified analysis of hot video schedulers. In Proceedings of the thiry-fourth annual ACM symposium on Theory of computing (STOC ’02). Association for Computing Machinery, New York, NY, USA, 179–188. DOI:https://doi-org.libproxy.mst.edu/10.1145/509907.509937

“In a VOD system, a hot video is often requested over a short period of time (say, Friday 7 p.m. to 9 p.m.). Due to the large number of clients and the long duration of a video, server delivery bandwidth is a very precious resource. Two approaches, piggybacking and skimming, are commonly used in VOD systems to reduce the bandwidth for handling requests for a hot video over different times. These approaches take advantage of the multicasting architecture (which allows the server to multicast a single video stream to many clients at the same time) to merge streams initiated at different times.

Piggybacking [1, 14, 15, 19] is based on the fact that a small deviation of the play rate is not perceived by viewers. The server can deliver a video stream in two rates, normal and fast. The fast play rate is achieved via sampling techniques instead of increasing the server bandwidth. A stream X can run in the fast rate to catch up an earlier stream Y running in normal rate. When the two streams are synchronized (i.e., both have played the same portion of the video), X can merge with Y, i.e., X can be terminated and all its clients switch to Y. This saves the bandwidth that should have been used by X. (See Figure 1 for an example.)

Skimming [3, 4, 8, 9, 10, 11, 12] assumes every client has a certain amount of extra receiving bandwidth to tap another stream. Hence, clients can listen to a stream X and receive extra data from an earlier stream Y at the same time. After a while, the clients will have buffered enough data from Y and they can count on Y solely. Then X can merge with Y. Note that the larger the client bandwidth, the earlier a merging can occur and thus the larger the server bandwidth is saved. (See Figure 2 for an example.)”

7.

Link: https://ieeexplore-ieee-org.libproxy.mst.edu/document/5174411

J. Kovacevic, D. Samardzija and M. Temerinac, "Joint coding rate control for audio streaming in short range wireless networks," in IEEE Transactions on Consumer Electronics, vol. 55, no. 2, pp. 486-491, May 2009.

“Streaming high quality audio/video (AV) from home media sources to TV sets and audio speakers over a wireless local area network (WLAN) is a challenging problem because of the fluctuating bandwidth caused by interference and fading. Retransmission and data buffering, as common techniques in data transfer over error-prone channels, are not adequate for delay sensitive applications such as high quality audio streaming. Our approach is to adjust the audio data rate dynamically in order to improve the perceptual quality of audio according to wireless channel quality.”

“Unlike the data applications, audio and video streaming are intolerant of bandwidth fluctuations due to the delay constraints. Guaranteed bandwidth and Quality-of-Service (QoS) are essential requirements in order to satisfy customer expectations for “wire-like” performance. Assuring high bandwidth is essential but not sufficient. When several applications try to access the same bandwidth, the ones that are intolerant to time delays and bandwidth fluctuations will not function properly”

8.

Link: https://ieeexplore-ieee-org.libproxy.mst.edu/document/8826710

K. Sun, H. Zhang, Y. Gao and D. Wu, "Delay-aware fountain codes for video streaming with optimal sampling strategy," in Journal of Communications and Networks, vol. 21, no. 4, pp. 339-352, Aug. 2019.

“To address this, we propose a novel delay-aware fountain coding (DAF) technique that integrates channel coding and video coding. In this paper, we reveal that the fluctuation of video bit rate can also be exploited to further improve fountain codes for wireless video streaming. Specifically, we develop two coding techniques: the time-based sliding window and the optimal window-wise sampling strategy. By adaptively selecting the window length and optimally adjusting the sampling pattern according to the ongoing video bit rate, the proposed schemes deliver significantly higher video quality than existing schemes, with low delay and constant data rate.”

“In the recent decade, we have witnessed the bloom of video services over the Internet. Some of them provide pre-recorded video streams such as YouTube and Netflix; others provide live video communications such as Skype and Facetime. As expected, a huge amount of multimedia contents will be generated and consumed. On the other hand, the prevalent smart mobile devices make these contents more accessible to people than ever. Thanks to the evolution of communication technologies, such as 3G/4G, LTE, WiFi, etc., wireless networks are widely available in our daily lives. However, despite the promising developments, the stochastic nature of wireless channels still persists: Its vulnerability to channel noise, inter-user interference and low data rate under mobility. The problems easily deteriorate in video-dominant applications where the requirement on channel quality is the highest. As a result, how to stream videos with low delay, stable data rate and high quality over wireless network raises formidable challenges in communication society.”

“To provide reliable video transmission, advanced coding and signal processing techniques, such as forward error correction (FEC) erasure codes, have been proposed. One important class of FEC codes are fountain codes [1], such as Luby transform (LT) code [2] and Raptor code [3]. Fountain codes are ideal for wireless video streaming for the following reasons: (i) Retransmission-free property: Fountain codes will reconstruct the original data using the redundancy sent by the sender, without demanding ACK or retransmission; (ii) efficient broEfficient broadcast/multicast: Different receivers can decode from different subsets of received packets as long as the number of received packets exceed a threshold; (iii) universality: The actual transmission rate will automatically approach channel capacity without the use of channel estimation, which has been proven in [4]. The traditional fountain codes are initially designed for achieving the complete decoding of the entire original file. That means, if a video file is transmitted using traditional fountain codes, users cannot watch it until the whole video file is successfully decoded. However, a lot of video streaming applications are delay-aware and loss-tolerant, which means (i) the time interval between video being generated and being played can not exceed a certain threshold; and (ii) partial decoding is tolerable, albeit higher decoding ratio is still preferred. In order to introduce delay awareness into fountain codes, the most intuitive solution is to partition the video file into fixed-length data blocks, separately encode them, and transmit sequentially. We call this method the block coding scheme. From the perspective of video transmission, a smaller block size is preferred, because it leads to shorter playback latency. From the perspective of fountain codes, however, the block size needs to be as big as possible to maintain a smaller coding overhead [5]. The fundamental tradeoff between video watching experience and coding performance is crucial for the design of delay-aware fountain codes.”

“Innovatively, we take into account video bit rate fluctuation and video coding parameters, such as group of pictures (GOP) size and frame rate, at the level of channel coding, and exploits them in the design of a novel delay-aware fountain coding approach. As a result, the proposed schemes take advantages of all the benefits of fountain codes, and optimize them in the context of delay-aware video applications.”

9.

https://ieeexplore-ieee-org.libproxy.mst.edu/document/6802715

Z. Chun-Hua, "MC-SPS: A Multi-core Based Streaming Media Packet Scheduling Algorithm," 2014 Sixth International Conference on Measuring Technology and Mechatronics Automation, Zhangjiajie, 2014, pp. 398-400.

“Streaming media packet processing is a typical streaming application, which is very sensitive and delay and delay jitter. Multi-core network processor has carried on the special optimization for high-speed network processing with advantages of flexible and efficient. FCFS scheduling algorithm can achieve load balance on packet, but can hardly reach cache affinity. The scheduling algorithm based on hash can guarantee affinity, but difficult to balance the load between processing cores.”

“The main goal of packet scheduling is to make full use of thecomputing resources of each processing core to reach load balancing and improve the system throughput. Currently stream packet scheduling aims at packets sequence preserving and load balancing [6-8]. These algorithms have good core affinity, but the researches mainly focused on inter-core load balancing without analyzing the impact of core affinity on system performance in detail.”

10.

Link: https://ieeexplore-ieee-org.libproxy.mst.edu/document/6948427

F. Zheng et al., "Minimizing latency for augmented reality displays: Frames considered harmful," 2014 IEEE International Symposium on Mixed and Augmented Reality (ISMAR), Munich, 2014, pp. 195-200.

“We minimize latency by updating selected parts of the displayed image—those that require the most change—instead of the complete image. Updating arbitrary individual pixels is generally not feasible; ideally, we would update small groups of pixels in parallel at a bandwidth as high or higher than current full-frame bandwidth. This leads to higher update rates, albeit of smaller display regions. While no currently available display accommodates this update mode, we propose a broad framework for the ideal device and then specialize the algorithm for an existing one.”

11.

https://ieeexplore-ieee-org.libproxy.mst.edu/document/5497499

Z. Ying-hui and T. Ai-ping, "Caching algorithm for streaming media on P2P network," 2010 2nd International Conference on Future Computer and Communication, Wuha, 2010, pp. V3-573-V3-576.

“P2P network has played an important role in the distribution of large data flow of streaming media in application The bandwidth of network and disk I/O is the main bottleneck to the transferring of real-time streaming media. Data caching technology is widely used in the area as a useful method to solve the problem. This paper proposed a streaming media caching algorithm based on peer to peer network, using the node’s access rate during the certain period of time to choose the caching node, at the same time it determine the size of data caching buffer according to the network’s bandwidth and node’s I/O bandwidth. The experimental results show that this algorithm is much better than other caching algorithm in the merit of reducing network load, reducing data delays and lower caching buffer.”

“This paper proposed a local caching algorithm based on the resource’s access rate, choosing the nodes with high access rate to cache the streaming media data, which reduces the network’s load resulting from huge query messages. At the same time our caching algorithm could save the caching space effectively to cache more data, so the whole system's performance is improved. The results of experimental show that this algorithm is much better than other caching algorithm in the merit of reducing network load, reducing data delays and lower caching buffer.”

“Streaming media is data that is delivered in a continuous stream to a client and that can be used as it arrives. Peer-to-peer (P2P) systems are distributed systems in which nodes of equal roles and capabilities exchange information and services directly with each other. P2P refers to applications that employ distributed resources to perform a function in a decentralized manner. At present, P2P streaming media is the most important technology in the application field of streaming media.”

12.

https://ieeexplore.ieee.org/document/48075

R. Holte, A. Mok, L. Rosier, I. Tulchinsky and D. Varvel, "The pinwheel: a real-time scheduling problem," [1989] Proceedings of the Twenty-Second Annual Hawaii International Conference on System Sciences. Volume II: Software Track, Kailua-Kona, HI, USA, 1989, pp. 693-702 vol.2.

“Some satellites transmit a piece of information for set the duration, then proceed with another piece of information. A ground station receiving from several such satellite and wishing to avoid that data loss faces a real-time scheduling problem. [...] “The Pinwheel” is a formalization of this problem.”

